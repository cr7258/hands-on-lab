{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Users/I576375/opt/anaconda3/lib/python3.9/site-packages (1.4.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/I576375/opt/anaconda3/lib/python3.9/site-packages (from openai) (3.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/I576375/opt/anaconda3/lib/python3.9/site-packages/distro-1.8.0-py3.9.egg (from openai) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/I576375/opt/anaconda3/lib/python3.9/site-packages (from openai) (0.23.3)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/I576375/opt/anaconda3/lib/python3.9/site-packages (from openai) (2.5.2)\n",
      "Requirement already satisfied: sniffio in /Users/I576375/opt/anaconda3/lib/python3.9/site-packages (from openai) (1.2.0)\n",
      "Requirement already satisfied: tqdm>4 in /Users/I576375/opt/anaconda3/lib/python3.9/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in /Users/I576375/opt/anaconda3/lib/python3.9/site-packages (from openai) (4.6.3)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/I576375/opt/anaconda3/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: certifi in /Users/I576375/opt/anaconda3/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (2022.12.7)\n",
      "Requirement already satisfied: httpcore<0.17.0,>=0.15.0 in /Users/I576375/opt/anaconda3/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (0.16.3)\n",
      "Requirement already satisfied: rfc3986[idna2008]<2,>=1.3 in /Users/I576375/opt/anaconda3/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (1.5.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/I576375/opt/anaconda3/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in /Users/I576375/opt/anaconda3/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->openai) (2.14.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/I576375/opt/anaconda3/lib/python3.9/site-packages (from httpcore<0.17.0,>=0.15.0->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def show_json(obj):\n",
    "    display(json.loads(obj.model_dump_json()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'asst_dwmMk99NSZ8nXfz8ttBZVsF3',\n",
       " 'created_at': 1702739530,\n",
       " 'description': None,\n",
       " 'file_ids': [],\n",
       " 'instructions': 'You are a helpful personal math tutor, Answer questions and show your work.',\n",
       " 'metadata': {},\n",
       " 'model': 'gpt-4-1106-preview',\n",
       " 'name': 'Math Tutor',\n",
       " 'object': 'assistant',\n",
       " 'tools': []}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "client = OpenAI()\n",
    "assistant = client.beta.assistants.create(\n",
    "    name=\"Math Tutor\",\n",
    "    instructions=\"You are a helpful personal math tutor, Answer questions and show your work.\",\n",
    "    model=\"gpt-4-1106-preview\"\n",
    ")\n",
    "show_json(assistant)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'thread_38nTOZfK8eiaSqIrpm8VUpIO',\n",
       " 'created_at': 1702739530,\n",
       " 'metadata': {},\n",
       " 'object': 'thread'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "thread = client.beta.threads.create()\n",
    "show_json(thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'msg_wIYikjg3ccJk2JbOoZ3h2S34',\n",
       " 'assistant_id': None,\n",
       " 'content': [{'text': {'annotations': [],\n",
       "    'value': 'I need to solve this problem: 3x + 11 = 14, can you help me?'},\n",
       "   'type': 'text'}],\n",
       " 'created_at': 1702739531,\n",
       " 'file_ids': [],\n",
       " 'metadata': {},\n",
       " 'object': 'thread.message',\n",
       " 'role': 'user',\n",
       " 'run_id': None,\n",
       " 'thread_id': 'thread_38nTOZfK8eiaSqIrpm8VUpIO'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"I need to solve this problem: 3x + 11 = 14, can you help me?\"\n",
    ")\n",
    "show_json(message) # 此时还没有真正请求 OpenAI 进行处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'run_35E0dk0jed3RzDRjikbeiYu4',\n",
       " 'assistant_id': 'asst_dwmMk99NSZ8nXfz8ttBZVsF3',\n",
       " 'cancelled_at': None,\n",
       " 'completed_at': None,\n",
       " 'created_at': 1702739531,\n",
       " 'expires_at': 1702740131,\n",
       " 'failed_at': None,\n",
       " 'file_ids': [],\n",
       " 'instructions': 'You are a helpful personal math tutor, Answer questions and show your work.',\n",
       " 'last_error': None,\n",
       " 'metadata': {},\n",
       " 'model': 'gpt-4-1106-preview',\n",
       " 'object': 'thread.run',\n",
       " 'required_action': None,\n",
       " 'started_at': None,\n",
       " 'status': 'queued',\n",
       " 'thread_id': 'thread_38nTOZfK8eiaSqIrpm8VUpIO',\n",
       " 'tools': []}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id\n",
    ")\n",
    "show_json(run)\n",
    "# 从输出可以看到 status 是 queued，说明 run 是异步执行的，我们需要写个方法来等待执行完成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def wait_on_run(run, thread):\n",
    "    while run.status == \"queued\" or run.status == \"in_progress\":\n",
    "        run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
    "        time.sleep(0.5)\n",
    "    return run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'run_35E0dk0jed3RzDRjikbeiYu4',\n",
       " 'assistant_id': 'asst_dwmMk99NSZ8nXfz8ttBZVsF3',\n",
       " 'cancelled_at': None,\n",
       " 'completed_at': 1702739540,\n",
       " 'created_at': 1702739531,\n",
       " 'expires_at': None,\n",
       " 'failed_at': None,\n",
       " 'file_ids': [],\n",
       " 'instructions': 'You are a helpful personal math tutor, Answer questions and show your work.',\n",
       " 'last_error': None,\n",
       " 'metadata': {},\n",
       " 'model': 'gpt-4-1106-preview',\n",
       " 'object': 'thread.run',\n",
       " 'required_action': None,\n",
       " 'started_at': 1702739532,\n",
       " 'status': 'completed',\n",
       " 'thread_id': 'thread_38nTOZfK8eiaSqIrpm8VUpIO',\n",
       " 'tools': []}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wait_on_run(run, thread)\n",
    "show_json(run) # 此时可以看到 status 是 completed，说明运行完成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': [{'id': 'msg_EaIPRHTVuT7MLJbnm4XxH6Ae',\n",
       "   'assistant_id': 'asst_dwmMk99NSZ8nXfz8ttBZVsF3',\n",
       "   'content': [{'text': {'annotations': [],\n",
       "      'value': \"Certainly! To solve for x in the equation 3x + 11 = 14, we want to isolate x on one side of the equation. Here's how we can do that step by step:\\n\\n1. Subtract 11 from both sides of the equation to get the term with x by itself on the left side:\\n\\n3x + 11 - 11 = 14 - 11\\n\\nThe 11s on the left cancel out, leaving us with:\\n\\n3x = 3\\n\\n2. Now, to solve for x, divide both sides of the equation by 3, which is the coefficient of x:\\n\\n3x / 3 = 3 / 3\\n\\nx = 1\\n\\nSo the solution to the equation is x = 1.\"},\n",
       "     'type': 'text'}],\n",
       "   'created_at': 1702739533,\n",
       "   'file_ids': [],\n",
       "   'metadata': {},\n",
       "   'object': 'thread.message',\n",
       "   'role': 'assistant',\n",
       "   'run_id': 'run_35E0dk0jed3RzDRjikbeiYu4',\n",
       "   'thread_id': 'thread_38nTOZfK8eiaSqIrpm8VUpIO'},\n",
       "  {'id': 'msg_wIYikjg3ccJk2JbOoZ3h2S34',\n",
       "   'assistant_id': None,\n",
       "   'content': [{'text': {'annotations': [],\n",
       "      'value': 'I need to solve this problem: 3x + 11 = 14, can you help me?'},\n",
       "     'type': 'text'}],\n",
       "   'created_at': 1702739531,\n",
       "   'file_ids': [],\n",
       "   'metadata': {},\n",
       "   'object': 'thread.message',\n",
       "   'role': 'user',\n",
       "   'run_id': None,\n",
       "   'thread_id': 'thread_38nTOZfK8eiaSqIrpm8VUpIO'}],\n",
       " 'object': 'list',\n",
       " 'first_id': 'msg_EaIPRHTVuT7MLJbnm4XxH6Ae',\n",
       " 'last_id': 'msg_wIYikjg3ccJk2JbOoZ3h2S34',\n",
       " 'has_more': False}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "message = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "show_json(message) # 打印结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': [{'id': 'msg_Qwm0JIi08GNx0O1gJn6EC3HO',\n",
       "   'assistant_id': 'asst_dwmMk99NSZ8nXfz8ttBZVsF3',\n",
       "   'content': [{'text': {'annotations': [],\n",
       "      'value': 'Certainly! Elasticsearch is a search engine based on the Lucene library and it\\'s designed to handle a variety of use-cases that involve the search and analysis of large amounts of data. Instead of a \"query cache\" similar to those found in traditional SQL databases, Elasticsearch uses a combination of different caching mechanisms to speed up searches, but it does not cache the actual results of queries in the same way a regular database might cache results of select statements.\\n\\nLet me explain the types of caches in Elasticsearch that contribute to improving search performance:\\n\\n1. **Node Query Cache**: Elasticsearch caches the filter part of search requests. Filters are deterministic, meaning that given a set of data and a filter query, the result is always going to be the same. Elasticsearch takes advantage of this to cache the result of the filter and use it for subsequent searches as long as the data within the shard doesn\\'t change. This cache exists at the node level and is called the node query cache.\\n\\n2. **Shard Request Cache**: The shard request cache is used to cache the output of entire search requests on a per-shard basis. This type of cache is most effective with aggregations where the result is expected to be reused often. The data in these caches is also invalidated when the contents of a shard change.\\n\\n3. **Field Data Cache**: When sorting or aggregating on a text field, Elasticsearch needs to convert this field into a numeric value. Since this operation can be costly in terms of CPU and I/O, Elasticsearch caches this numerical representation to avoid recomputing it.\\n\\nThese caches help Elasticsearch avoid doing repetitive work when searches are performed, but it\\'s important to note that the actual decision-making and set-up of these mechanisms are often quite complex and rely on sensible defaults that work well out of the box for most use cases.\\n\\nHere are some general tips for cache effectiveness:\\n\\n- Write queries to make good use of the `filter` context for conditions that don\\'t score the document but only include/exclude documents based on criteria.\\n  \\n- Reuse the same filter conditions in your queries wherever possible to improve the likelihood of cache hits.\\n\\n- Remember that cache settings can affect the memory footprint of your Elasticsearch nodes.\\n\\nConfiguring caches needs a nuanced approach and should be based on an understanding of your data and the nature of your queries. Over-caching can lead to memory pressure while under-caching can lead to slower query responses.\\n\\nFor the exact methods to configure settings like cache sizes and expiration, you would refer to the specific version of the Elasticsearch documentation since these settings can change over time and between different versions.\\n\\nHopefully, this explanation gives you a clearer understanding of how Elasticsearch manages caching at a high level. Remember to consult the documentation or the community for the specifics of the version of Elasticsearch you are using.'},\n",
       "     'type': 'text'}],\n",
       "   'created_at': 1702739666,\n",
       "   'file_ids': [],\n",
       "   'metadata': {},\n",
       "   'object': 'thread.message',\n",
       "   'role': 'assistant',\n",
       "   'run_id': 'run_PjedT9L7XEmvzs9WoSP4GpLb',\n",
       "   'thread_id': 'thread_38nTOZfK8eiaSqIrpm8VUpIO'}],\n",
       " 'object': 'list',\n",
       " 'first_id': 'msg_Qwm0JIi08GNx0O1gJn6EC3HO',\n",
       " 'last_id': 'msg_Qwm0JIi08GNx0O1gJn6EC3HO',\n",
       " 'has_more': False}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 连续对话\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"Can you explain this to me?\"\n",
    ")\n",
    "\n",
    "run = client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id\n",
    ")\n",
    "\n",
    "wait_on_run(run, thread)\n",
    "message = client.beta.threads.messages.list(thread_id=thread.id, order=\"asc\", after=message.id)\n",
    "show_json(message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
