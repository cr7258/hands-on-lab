{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Users/I576375/opt/anaconda3/lib/python3.9/site-packages (1.4.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/I576375/opt/anaconda3/lib/python3.9/site-packages (from openai) (3.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/I576375/opt/anaconda3/lib/python3.9/site-packages/distro-1.8.0-py3.9.egg (from openai) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/I576375/opt/anaconda3/lib/python3.9/site-packages (from openai) (0.23.3)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/I576375/opt/anaconda3/lib/python3.9/site-packages (from openai) (2.5.2)\n",
      "Requirement already satisfied: sniffio in /Users/I576375/opt/anaconda3/lib/python3.9/site-packages (from openai) (1.2.0)\n",
      "Requirement already satisfied: tqdm>4 in /Users/I576375/opt/anaconda3/lib/python3.9/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in /Users/I576375/opt/anaconda3/lib/python3.9/site-packages (from openai) (4.6.3)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/I576375/opt/anaconda3/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: certifi in /Users/I576375/opt/anaconda3/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (2022.12.7)\n",
      "Requirement already satisfied: httpcore<0.17.0,>=0.15.0 in /Users/I576375/opt/anaconda3/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (0.16.3)\n",
      "Requirement already satisfied: rfc3986[idna2008]<2,>=1.3 in /Users/I576375/opt/anaconda3/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (1.5.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/I576375/opt/anaconda3/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in /Users/I576375/opt/anaconda3/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->openai) (2.14.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/I576375/opt/anaconda3/lib/python3.9/site-packages (from httpcore<0.17.0,>=0.15.0->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def show_json(obj):\n",
    "    display(json.loads(obj.model_dump_json()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "thread = client.beta.threads.create()\n",
    "\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"Please tell me how to set query cache in Elasticsearch?\"\n",
    ")\n",
    "\n",
    "run = client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=\"asst_7hoiafTNjVIRy2IVJwQp3Ojy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def wait_on_run(run, thread):\n",
    "    while run.status == \"queued\" or run.status == \"in_progress\":\n",
    "        run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
    "        time.sleep(0.5)\n",
    "    return run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'run_Sw4EsS3Mp1Mf8SpQ9FHj2JZS',\n",
       " 'assistant_id': 'asst_7hoiafTNjVIRy2IVJwQp3Ojy',\n",
       " 'cancelled_at': None,\n",
       " 'completed_at': 1702739112,\n",
       " 'created_at': 1702739076,\n",
       " 'expires_at': None,\n",
       " 'failed_at': None,\n",
       " 'file_ids': ['file-LYzpZWL6wN2AYNUs0FU9slK1',\n",
       "  'file-fFLrcjZINdUzL2L8roYFOscX',\n",
       "  'file-3A1cwKAk4gNOkTXmyxSXuWU6'],\n",
       " 'instructions': None,\n",
       " 'last_error': None,\n",
       " 'metadata': {},\n",
       " 'model': 'gpt-4-1106-preview',\n",
       " 'object': 'thread.run',\n",
       " 'required_action': None,\n",
       " 'started_at': 1702739077,\n",
       " 'status': 'completed',\n",
       " 'thread_id': 'thread_5UZ7idZBq6hW740EUlIrpfBi',\n",
       " 'tools': [{'type': 'retrieval'}]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wait_on_run(run, thread)\n",
    "show_json(run) # 此时可以看到 status 是 completed，说明运行完成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': [{'id': 'msg_ZaIJ9GRnLCloKjJkSu1Zeso7',\n",
       "   'assistant_id': 'asst_7hoiafTNjVIRy2IVJwQp3Ojy',\n",
       "   'content': [{'text': {'annotations': [],\n",
       "      'value': 'In Elasticsearch, query caching can help improve search performance by caching the results of certain filters or queries which do not change often. Here\\'s how you can set up and use query caching:\\n\\n1. **Node Query Cache**: This is active by default for all nodes in the cluster. Elasticsearch keeps the results of frequently used queries in the cache. You can see the status of the node query cache using the `_nodes/stats/indices/query_cache` API.\\n\\n2. **Shard Request Cache**: This cache is used for the results of search requests on a per-shard basis and is particularly useful for caching the results of aggregations.\\n\\n    To enable the shard request cache for a particular index, you can set the `index.requests.cache.enable` setting to `true`. This can be done when creating an index or updating settings for an existing index.\\n\\nHere are the steps:\\n\\n- **Creating an Index with Request Cache Enabled:**\\n    ```json\\n    PUT /my_index\\n    {\\n        \"settings\": {\\n            \"index.requests.cache.enable\": true\\n        }\\n    }\\n    ```\\n\\n- **Updating Settings for an Existing Index:**\\n    ```json\\n    PUT /my_index/_settings\\n    {\\n        \"index.requests.cache.enable\": true\\n    }\\n    ```\\n\\n3. **Fine-Tuning Cache Settings**: You can also fine-tune the cache size and the individual settings through the `elasticsearch.yml` configuration file or dynamically via the cluster update settings API.\\n\\n    Examples of settings include:\\n    - `indices.requests.cache.size`: The percentage of heap space allocated for the request cache.\\n    - `indices.requests.cache.expire`: The expire time for the cache entries.\\n\\n4. **Understanding Cache**: The query cache works by caching the document set produced by filters and queries. It caches the result set of the Lucene index, not the JSON response. This means it\\'s most efficient for queries and filters that are used as part of many different searches.\\n\\n5. **Using the Cache in Queries**: When you make a query request, you can use the `request_cache` parameter to indicate whether you want to use the cache for that request. Set `request_cache=true` to force query caching, whereas `false` will bypass the cache.\\n\\n    ```json\\n    GET /my_index/_search\\n    {\\n        \"size\": 0,\\n        \"query\": {\\n            \"term\": {\\n                \"status\": \"active\"\\n            }\\n        },\\n        \"aggs\": {\\n            \"my_aggregation\": {\\n                \"terms\": {\\n                    \"field\": \"user_id\"\\n                }\\n            }\\n        },\\n        \"request_cache\": true\\n    }\\n    ```\\n\\n6. **Monitoring and Clearing Cache**: You can monitor the effectiveness of your caches through the Elasticsearch `_stats` endpoint and clear the cache using the `_cache/clear` endpoint.\\n\\nIt\\'s important to mention that excessive or inappropriate use of caching can lead to increased memory usage and could potentially affect the performance negatively if not managed carefully. It\\'s best to use caching for scenarios where you expect a significant performance improvement due to repetitive and expensive queries. Always test and monitor the impact of enabling cache on your systems.'},\n",
       "     'type': 'text'}],\n",
       "   'created_at': 1702739077,\n",
       "   'file_ids': [],\n",
       "   'metadata': {},\n",
       "   'object': 'thread.message',\n",
       "   'role': 'assistant',\n",
       "   'run_id': 'run_Sw4EsS3Mp1Mf8SpQ9FHj2JZS',\n",
       "   'thread_id': 'thread_5UZ7idZBq6hW740EUlIrpfBi'},\n",
       "  {'id': 'msg_OartVWFA2LQ3vAGryE7o0w5t',\n",
       "   'assistant_id': None,\n",
       "   'content': [{'text': {'annotations': [],\n",
       "      'value': 'Please tell me how to set query cache in Elasticsearch?'},\n",
       "     'type': 'text'}],\n",
       "   'created_at': 1702739076,\n",
       "   'file_ids': [],\n",
       "   'metadata': {},\n",
       "   'object': 'thread.message',\n",
       "   'role': 'user',\n",
       "   'run_id': None,\n",
       "   'thread_id': 'thread_5UZ7idZBq6hW740EUlIrpfBi'}],\n",
       " 'object': 'list',\n",
       " 'first_id': 'msg_ZaIJ9GRnLCloKjJkSu1Zeso7',\n",
       " 'last_id': 'msg_OartVWFA2LQ3vAGryE7o0w5t',\n",
       " 'has_more': False}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "message = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "show_json(message) # 打印结果"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
