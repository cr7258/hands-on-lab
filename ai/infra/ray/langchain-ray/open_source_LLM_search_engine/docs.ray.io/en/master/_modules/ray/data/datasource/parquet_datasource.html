
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>ray.data.datasource.parquet_datasource &#8212; Ray 3.0.0.dev0</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../../_static/styles/theme.css@digest=1999514e3f237ded88cf.css" rel="stylesheet">
<link href="../../../../_static/styles/pydata-sphinx-theme.css@digest=1999514e3f237ded88cf.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../../_static/styles/sphinx-book-theme.css@digest=5115cc725059bd94278eecd172e13a965bf8f5a9.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/autodoc_pydantic.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/css/custom.css" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/css/termynal.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css" />
    <link rel="stylesheet" type="text/css" href="../../../../../../_/static/css/badge_only.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../../_static/scripts/pydata-sphinx-theme.js@digest=1999514e3f237ded88cf">

    <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
    <script src="../../../../_static/jquery.js"></script>
    <script src="../../../../_static/underscore.js"></script>
    <script src="../../../../_static/doctools.js"></script>
    <script src="../../../../_static/clipboard.min.js"></script>
    <script src="../../../../_static/copybutton.js"></script>
    <script src="../../../../_static/js/versionwarning.js"></script>
    <script src="../../../../_static/togglebutton.js"></script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js"></script>
    <script defer="defer" src="../../../../_static/js/docsearch.js"></script>
    <script src="../../../../_static/js/rate-the-docs.es.min.js"></script>
    <script defer="defer" src="../../../../_static/js/termynal.js"></script>
    <script defer="defer" src="../../../../_static/js/custom.js"></script>
    <script defer="defer" src="../../../../_static/js/top-navigation.js"></script>
    <script src="../../../../_static/js/tags.js"></script>
    <script src="../../../../_static/tabs.js"></script>
    <script src="../../../../_static/scripts/sphinx-book-theme.js@digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../../_static/design-tabs.js"></script>
    <script async="async" src="../../../../../../_/static/javascript/readthedocs-doc-embed.js"></script>
    <link rel="canonical" href="https://docs.ray.io/en/latest/_modules/ray/data/datasource/parquet_datasource.html" />
    <link rel="shortcut icon" href="../../../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />

<!-- Fathom - beautiful, simple website analytics -->
<script src="https://deer.ray.io/script.js" data-site="WYYANYOS" defer></script>
<!-- / Fathom -->

<script async src="https://www.googletagmanager.com/gtag/js?id=UA-110413294-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-110413294-1');
</script>


  
<!-- RTD Extra Head -->

<link rel="stylesheet" href="../../../../../../_/static/css/readthedocs-doc-embed.css" type="text/css" />

<script type="application/json" id="READTHEDOCS_DATA">{"ad_free": false, "api_host": "https://readthedocs.com", "build_date": "2023-04-28T22:35:11Z", "builder": "sphinx", "canonical_url": null, "commit": "ff36b8e7", "docroot": "/doc/source/", "features": {"docsearch_disabled": false}, "global_analytics_code": "UA-17997319-2", "language": "en", "page": "_modules/ray/data/datasource/parquet_datasource", "programming_language": "py", "project": "anyscale-ray", "proxied_api_host": "/_", "source_suffix": ".rst", "subprojects": {}, "theme": "sphinx_book_theme", "user_analytics_code": "", "version": "master"}</script>

<!--
Using this variable directly instead of using `JSON.parse` is deprecated.
The READTHEDOCS_DATA global variable will be removed in the future.
-->
<script type="text/javascript">
READTHEDOCS_DATA = JSON.parse(document.getElementById('READTHEDOCS_DATA').innerHTML);
</script>

<script type="text/javascript" src="../../../../../../_/static/javascript/readthedocs-analytics.js" async="async"></script>

<!-- end RTD <extrahead> -->
</head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"><div class='topnav'></div></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../../../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Ray 3.0.0.dev0</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main Navigation">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../../../index.html">
                    Welcome to Ray!
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Ray
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-overview/index.html">
   Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-overview/getting-started.html">
   Getting Started Guide
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-more-libs/installation.html">
   Installation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-overview/use-cases.html">
   Use Cases
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-overview/ray-libraries.html">
   Ecosystem
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-core/walkthrough.html">
   Ray Core
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-air/getting-started.html">
   Ray AI Runtime (AIR)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../data/data.html">
   Ray Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../train/train.html">
   Ray Train
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../tune.html">
   Ray Tune
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../serve/index.html">
   Ray Serve
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../rllib/index.html">
   Ray RLlib
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-more-libs/index.html">
   More Libraries
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-core/cluster/index.html">
   Ray Clusters
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-observability/monitoring-debugging/monitoring-debugging.html">
   Monitoring and Debugging
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-references/api.html">
   References
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../ray-contribute/stability.html">
   Developer Guides
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/ray-project/ray"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/ray-project/ray/issues/new?title=Issue%20on%20page%20%2F_modules/ray/data/datasource/parquet_datasource.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1></h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <h1>Source code for ray.data.datasource.parquet_datasource</h1><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">TYPE_CHECKING</span><span class="p">,</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Iterator</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">ray.data._internal.output_buffer</span> <span class="kn">import</span> <span class="n">BlockOutputBuffer</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.progress_bar</span> <span class="kn">import</span> <span class="n">ProgressBar</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.remote_fn</span> <span class="kn">import</span> <span class="n">cached_remote_fn</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.util</span> <span class="kn">import</span> <span class="n">_check_pyarrow_version</span>
<span class="kn">from</span> <span class="nn">ray.data.block</span> <span class="kn">import</span> <span class="n">Block</span>
<span class="kn">from</span> <span class="nn">ray.data.context</span> <span class="kn">import</span> <span class="n">DataContext</span>
<span class="kn">from</span> <span class="nn">ray.data.datasource.datasource</span> <span class="kn">import</span> <span class="n">Reader</span><span class="p">,</span> <span class="n">ReadTask</span>
<span class="kn">from</span> <span class="nn">ray.data.datasource.file_based_datasource</span> <span class="kn">import</span> <span class="n">_resolve_paths_and_filesystem</span>
<span class="kn">from</span> <span class="nn">ray.data.datasource.file_meta_provider</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">DefaultParquetMetadataProvider</span><span class="p">,</span>
    <span class="n">ParquetMetadataProvider</span><span class="p">,</span>
    <span class="n">_handle_read_os_error</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">ray.data.datasource.parquet_base_datasource</span> <span class="kn">import</span> <span class="n">ParquetBaseDatasource</span>
<span class="kn">from</span> <span class="nn">ray.util.annotations</span> <span class="kn">import</span> <span class="n">PublicAPI</span>
<span class="kn">import</span> <span class="nn">ray.cloudpickle</span> <span class="k">as</span> <span class="nn">cloudpickle</span>

<span class="k">if</span> <span class="n">TYPE_CHECKING</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">pyarrow</span>
    <span class="kn">from</span> <span class="nn">pyarrow.dataset</span> <span class="kn">import</span> <span class="n">ParquetFileFragment</span>


<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>

<span class="n">PIECES_PER_META_FETCH</span> <span class="o">=</span> <span class="mi">6</span>
<span class="n">PARALLELIZE_META_FETCH_THRESHOLD</span> <span class="o">=</span> <span class="mi">24</span>

<span class="c1"># The number of rows to read per batch. This is sized to generate 10MiB batches</span>
<span class="c1"># for rows about 1KiB in size.</span>
<span class="n">PARQUET_READER_ROW_BATCH_SIZE</span> <span class="o">=</span> <span class="mi">100000</span>
<span class="n">FILE_READING_RETRY</span> <span class="o">=</span> <span class="mi">8</span>

<span class="c1"># The default size multiplier for reading Parquet data source in Arrow.</span>
<span class="c1"># Parquet data format is encoded with various encoding techniques (such as</span>
<span class="c1"># dictionary, RLE, delta), so Arrow in-memory representation uses much more memory</span>
<span class="c1"># compared to Parquet encoded representation. Parquet file statistics only record</span>
<span class="c1"># encoded (i.e. uncompressed) data size information.</span>
<span class="c1">#</span>
<span class="c1"># To estimate real-time in-memory data size, Datastreams will try to estimate the</span>
<span class="c1"># correct inflation ratio from Parquet to Arrow, using this constant as the default</span>
<span class="c1"># value for safety. See https://github.com/ray-project/ray/pull/26516 for more context.</span>
<span class="n">PARQUET_ENCODING_RATIO_ESTIMATE_DEFAULT</span> <span class="o">=</span> <span class="mi">5</span>

<span class="c1"># The lower bound size to estimate Parquet encoding ratio.</span>
<span class="n">PARQUET_ENCODING_RATIO_ESTIMATE_LOWER_BOUND</span> <span class="o">=</span> <span class="mi">2</span>

<span class="c1"># The percentage of files (1% by default) to be sampled from the datastream to estimate</span>
<span class="c1"># Parquet encoding ratio.</span>
<span class="n">PARQUET_ENCODING_RATIO_ESTIMATE_SAMPLING_RATIO</span> <span class="o">=</span> <span class="mf">0.01</span>

<span class="c1"># The minimal and maximal number of file samples to take from the datastream to estimate</span>
<span class="c1"># Parquet encoding ratio.</span>
<span class="c1"># This is to restrict `PARQUET_ENCODING_RATIO_ESTIMATE_SAMPLING_RATIO` within the</span>
<span class="c1"># proper boundary.</span>
<span class="n">PARQUET_ENCODING_RATIO_ESTIMATE_MIN_NUM_SAMPLES</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">PARQUET_ENCODING_RATIO_ESTIMATE_MAX_NUM_SAMPLES</span> <span class="o">=</span> <span class="mi">10</span>

<span class="c1"># The number of rows to read from each file for sampling. Try to keep it low to avoid</span>
<span class="c1"># reading too much data into memory.</span>
<span class="n">PARQUET_ENCODING_RATIO_ESTIMATE_NUM_ROWS</span> <span class="o">=</span> <span class="mi">1024</span>


<span class="c1"># TODO(ekl) this is a workaround for a pyarrow serialization bug, where serializing a</span>
<span class="c1"># raw pyarrow file fragment causes S3 network calls.</span>
<span class="k">class</span> <span class="nc">_SerializedPiece</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">frag</span><span class="p">:</span> <span class="s2">&quot;ParquetFileFragment&quot;</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_data</span> <span class="o">=</span> <span class="n">cloudpickle</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span>
            <span class="p">(</span><span class="n">frag</span><span class="o">.</span><span class="n">format</span><span class="p">,</span> <span class="n">frag</span><span class="o">.</span><span class="n">path</span><span class="p">,</span> <span class="n">frag</span><span class="o">.</span><span class="n">filesystem</span><span class="p">,</span> <span class="n">frag</span><span class="o">.</span><span class="n">partition_expression</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">deserialize</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;ParquetFileFragment&quot;</span><span class="p">:</span>
        <span class="c1"># Implicitly trigger S3 subsystem initialization by importing</span>
        <span class="c1"># pyarrow.fs.</span>
        <span class="kn">import</span> <span class="nn">pyarrow.fs</span>  <span class="c1"># noqa: F401</span>

        <span class="p">(</span><span class="n">file_format</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="n">filesystem</span><span class="p">,</span> <span class="n">partition_expression</span><span class="p">)</span> <span class="o">=</span> <span class="n">cloudpickle</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_data</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">file_format</span><span class="o">.</span><span class="n">make_fragment</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">filesystem</span><span class="p">,</span> <span class="n">partition_expression</span><span class="p">)</span>


<span class="c1"># Visible for test mocking.</span>
<span class="k">def</span> <span class="nf">_deserialize_pieces</span><span class="p">(</span>
    <span class="n">serialized_pieces</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">_SerializedPiece</span><span class="p">],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="s2">&quot;pyarrow._dataset.ParquetFileFragment&quot;</span><span class="p">]:</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">deserialize</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">serialized_pieces</span><span class="p">]</span>


<span class="c1"># This retry helps when the upstream datasource is not able to handle</span>
<span class="c1"># overloaded read request or failed with some retriable failures.</span>
<span class="c1"># For example when reading data from HA hdfs service, hdfs might</span>
<span class="c1"># lose connection for some unknown reason expecially when</span>
<span class="c1"># simutaneously running many hyper parameter tuning jobs</span>
<span class="c1"># with ray.data parallelism setting at high value like the default 200</span>
<span class="c1"># Such connection failure can be restored with some waiting and retry.</span>
<span class="k">def</span> <span class="nf">_deserialize_pieces_with_retry</span><span class="p">(</span>
    <span class="n">serialized_pieces</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">_SerializedPiece</span><span class="p">],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="s2">&quot;pyarrow._dataset.ParquetFileFragment&quot;</span><span class="p">]:</span>
    <span class="n">min_interval</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">final_exception</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">FILE_READING_RETRY</span><span class="p">):</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">_deserialize_pieces</span><span class="p">(</span><span class="n">serialized_pieces</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="kn">import</span> <span class="nn">random</span>
            <span class="kn">import</span> <span class="nn">time</span>

            <span class="n">retry_timing</span> <span class="o">=</span> <span class="p">(</span>
                <span class="s2">&quot;&quot;</span>
                <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="n">FILE_READING_RETRY</span> <span class="o">-</span> <span class="mi">1</span>
                <span class="k">else</span> <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Retry after </span><span class="si">{</span><span class="n">min_interval</span><span class="si">}</span><span class="s2"> sec. &quot;</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">log_only_show_in_1st_retry</span> <span class="o">=</span> <span class="p">(</span>
                <span class="s2">&quot;&quot;</span>
                <span class="k">if</span> <span class="n">i</span>
                <span class="k">else</span> <span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;If earlier read attempt threw certain Exception&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;, it may or may not be an issue depends on these retries &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;succeed or not. serialized_pieces:</span><span class="si">{</span><span class="n">serialized_pieces</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
            <span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">exception</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="si">}</span><span class="s2">th attempt to deserialize ParquetFileFragment failed. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">retry_timing</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">log_only_show_in_1st_retry</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">min_interval</span><span class="p">:</span>
                <span class="c1"># to make retries of different process hit hdfs server</span>
                <span class="c1"># at slightly different time</span>
                <span class="n">min_interval</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span>
            <span class="c1"># exponential backoff at</span>
            <span class="c1"># 1, 2, 4, 8, 16, 32, 64</span>
            <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="n">min_interval</span><span class="p">)</span>
            <span class="n">min_interval</span> <span class="o">=</span> <span class="n">min_interval</span> <span class="o">*</span> <span class="mi">2</span>
            <span class="n">final_exception</span> <span class="o">=</span> <span class="n">e</span>
    <span class="k">raise</span> <span class="n">final_exception</span>


<div class="viewcode-block" id="ParquetDatasource"><a class="viewcode-back" href="../../../../data/api/doc/ray.data.datasource.ParquetDatasource.html#ray.data.datasource.ParquetDatasource">[docs]</a><span class="nd">@PublicAPI</span>
<span class="k">class</span> <span class="nc">ParquetDatasource</span><span class="p">(</span><span class="n">ParquetBaseDatasource</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Parquet datasource, for reading and writing Parquet files.</span>

<span class="sd">    The primary difference from ParquetBaseDatasource is that this uses</span>
<span class="sd">    PyArrow&#39;s `ParquetDataset` abstraction for datastream reads, and thus offers</span>
<span class="sd">    automatic Arrow datastream schema inference and row count collection at the</span>
<span class="sd">    cost of some potential performance and/or compatibility penalties.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import ray</span>
<span class="sd">        &gt;&gt;&gt; from ray.data.datasource import ParquetDatasource</span>
<span class="sd">        &gt;&gt;&gt; source = ParquetDatasource() # doctest: +SKIP</span>
<span class="sd">        &gt;&gt;&gt; ray.data.read_datasource( # doctest: +SKIP</span>
<span class="sd">        ...     source, paths=&quot;/path/to/dir&quot;).take()</span>
<span class="sd">        [{&quot;a&quot;: 1, &quot;b&quot;: &quot;foo&quot;}, ...]</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="ParquetDatasource.get_name"><a class="viewcode-back" href="../../../../data/api/doc/ray.data.datasource.ParquetDatasource.get_name.html#ray.data.datasource.ParquetDatasource.get_name">[docs]</a>    <span class="k">def</span> <span class="nf">get_name</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return a human-readable name for this datasource.</span>
<span class="sd">        This will be used as the names of the read tasks.</span>
<span class="sd">        Note: overrides the base `ParquetBaseDatasource` method.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="s2">&quot;Parquet&quot;</span></div>

    <span class="k">def</span> <span class="nf">create_reader</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">_ParquetDatasourceReader</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>


<span class="k">class</span> <span class="nc">_ParquetDatasourceReader</span><span class="p">(</span><span class="n">Reader</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">paths</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
        <span class="n">local_uri</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">filesystem</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;pyarrow.fs.FileSystem&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">columns</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">schema</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">type</span><span class="p">,</span> <span class="s2">&quot;pyarrow.lib.Schema&quot;</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">meta_provider</span><span class="p">:</span> <span class="n">ParquetMetadataProvider</span> <span class="o">=</span> <span class="n">DefaultParquetMetadataProvider</span><span class="p">(),</span>
        <span class="n">_block_udf</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Block</span><span class="p">],</span> <span class="n">Block</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">reader_args</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="n">_check_pyarrow_version</span><span class="p">()</span>
        <span class="kn">import</span> <span class="nn">pyarrow</span> <span class="k">as</span> <span class="nn">pa</span>
        <span class="kn">import</span> <span class="nn">pyarrow.parquet</span> <span class="k">as</span> <span class="nn">pq</span>

        <span class="n">paths</span><span class="p">,</span> <span class="n">filesystem</span> <span class="o">=</span> <span class="n">_resolve_paths_and_filesystem</span><span class="p">(</span><span class="n">paths</span><span class="p">,</span> <span class="n">filesystem</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">paths</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">paths</span> <span class="o">=</span> <span class="n">paths</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_local_scheduling</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">local_uri</span><span class="p">:</span>
            <span class="kn">import</span> <span class="nn">ray</span>
            <span class="kn">from</span> <span class="nn">ray.util.scheduling_strategies</span> <span class="kn">import</span> <span class="n">NodeAffinitySchedulingStrategy</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_local_scheduling</span> <span class="o">=</span> <span class="n">NodeAffinitySchedulingStrategy</span><span class="p">(</span>
                <span class="n">ray</span><span class="o">.</span><span class="n">get_runtime_context</span><span class="p">()</span><span class="o">.</span><span class="n">get_node_id</span><span class="p">(),</span> <span class="n">soft</span><span class="o">=</span><span class="kc">False</span>
            <span class="p">)</span>

        <span class="n">dataset_kwargs</span> <span class="o">=</span> <span class="n">reader_args</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;dataset_kwargs&quot;</span><span class="p">,</span> <span class="p">{})</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">pq_ds</span> <span class="o">=</span> <span class="n">pq</span><span class="o">.</span><span class="n">ParquetDataset</span><span class="p">(</span>
                <span class="n">paths</span><span class="p">,</span>
                <span class="o">**</span><span class="n">dataset_kwargs</span><span class="p">,</span>
                <span class="n">filesystem</span><span class="o">=</span><span class="n">filesystem</span><span class="p">,</span>
                <span class="n">use_legacy_dataset</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">except</span> <span class="ne">OSError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">_handle_read_os_error</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">paths</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">schema</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">schema</span> <span class="o">=</span> <span class="n">pq_ds</span><span class="o">.</span><span class="n">schema</span>
        <span class="k">if</span> <span class="n">columns</span><span class="p">:</span>
            <span class="n">schema</span> <span class="o">=</span> <span class="n">pa</span><span class="o">.</span><span class="n">schema</span><span class="p">(</span>
                <span class="p">[</span><span class="n">schema</span><span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="n">column</span><span class="p">)</span> <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">columns</span><span class="p">],</span> <span class="n">schema</span><span class="o">.</span><span class="n">metadata</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">_block_udf</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Try to infer datastream schema by passing dummy table through UDF.</span>
            <span class="n">dummy_table</span> <span class="o">=</span> <span class="n">schema</span><span class="o">.</span><span class="n">empty_table</span><span class="p">()</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">inferred_schema</span> <span class="o">=</span> <span class="n">_block_udf</span><span class="p">(</span><span class="n">dummy_table</span><span class="p">)</span><span class="o">.</span><span class="n">schema</span>
                <span class="n">inferred_schema</span> <span class="o">=</span> <span class="n">inferred_schema</span><span class="o">.</span><span class="n">with_metadata</span><span class="p">(</span><span class="n">schema</span><span class="o">.</span><span class="n">metadata</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
                    <span class="s2">&quot;Failed to infer schema of datastream by passing dummy table &quot;</span>
                    <span class="s2">&quot;through UDF due to the following exception:&quot;</span><span class="p">,</span>
                    <span class="n">exc_info</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">inferred_schema</span> <span class="o">=</span> <span class="n">schema</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">inferred_schema</span> <span class="o">=</span> <span class="n">schema</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="n">prefetch_remote_args</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_local_scheduling</span><span class="p">:</span>
                <span class="n">prefetch_remote_args</span><span class="p">[</span><span class="s2">&quot;scheduling_strategy&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_local_scheduling</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_metadata</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">meta_provider</span><span class="o">.</span><span class="n">prefetch_file_metadata</span><span class="p">(</span>
                    <span class="n">pq_ds</span><span class="o">.</span><span class="n">pieces</span><span class="p">,</span> <span class="o">**</span><span class="n">prefetch_remote_args</span>
                <span class="p">)</span>
                <span class="ow">or</span> <span class="p">[]</span>
            <span class="p">)</span>
        <span class="k">except</span> <span class="ne">OSError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">_handle_read_os_error</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">paths</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_pq_ds</span> <span class="o">=</span> <span class="n">pq_ds</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_meta_provider</span> <span class="o">=</span> <span class="n">meta_provider</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_inferred_schema</span> <span class="o">=</span> <span class="n">inferred_schema</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_block_udf</span> <span class="o">=</span> <span class="n">_block_udf</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_reader_args</span> <span class="o">=</span> <span class="n">reader_args</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_columns</span> <span class="o">=</span> <span class="n">columns</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_schema</span> <span class="o">=</span> <span class="n">schema</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_encoding_ratio</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_estimate_files_encoding_ratio</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">estimate_inmemory_data_size</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
        <span class="n">total_size</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">file_metadata</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_metadata</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">row_group_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">file_metadata</span><span class="o">.</span><span class="n">num_row_groups</span><span class="p">):</span>
                <span class="n">row_group_metadata</span> <span class="o">=</span> <span class="n">file_metadata</span><span class="o">.</span><span class="n">row_group</span><span class="p">(</span><span class="n">row_group_idx</span><span class="p">)</span>
                <span class="n">total_size</span> <span class="o">+=</span> <span class="n">row_group_metadata</span><span class="o">.</span><span class="n">total_byte_size</span>
        <span class="k">return</span> <span class="n">total_size</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_encoding_ratio</span>

    <span class="k">def</span> <span class="nf">get_read_tasks</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">parallelism</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">ReadTask</span><span class="p">]:</span>
        <span class="c1"># NOTE: We override the base class FileBasedDatasource.get_read_tasks()</span>
        <span class="c1"># method in order to leverage pyarrow&#39;s ParquetDataset abstraction,</span>
        <span class="c1"># which simplifies partitioning logic. We still use</span>
        <span class="c1"># FileBasedDatasource&#39;s write side (do_write), however.</span>
        <span class="n">read_tasks</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">pieces</span><span class="p">,</span> <span class="n">metadata</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">array_split</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_pq_ds</span><span class="o">.</span><span class="n">pieces</span><span class="p">,</span> <span class="n">parallelism</span><span class="p">),</span>
            <span class="n">np</span><span class="o">.</span><span class="n">array_split</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_metadata</span><span class="p">,</span> <span class="n">parallelism</span><span class="p">),</span>
        <span class="p">):</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">pieces</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="n">serialized_pieces</span> <span class="o">=</span> <span class="p">[</span><span class="n">_SerializedPiece</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">pieces</span><span class="p">]</span>
            <span class="n">input_files</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">path</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">pieces</span><span class="p">]</span>
            <span class="n">meta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_meta_provider</span><span class="p">(</span>
                <span class="n">input_files</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_inferred_schema</span><span class="p">,</span>
                <span class="n">pieces</span><span class="o">=</span><span class="n">pieces</span><span class="p">,</span>
                <span class="n">prefetched_metadata</span><span class="o">=</span><span class="n">metadata</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="c1"># If there is a filter operation, reset the calculated row count,</span>
            <span class="c1"># since the resulting row count is unknown.</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_reader_args</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;filter&quot;</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">meta</span><span class="o">.</span><span class="n">num_rows</span> <span class="o">=</span> <span class="kc">None</span>

            <span class="k">if</span> <span class="n">meta</span><span class="o">.</span><span class="n">size_bytes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">meta</span><span class="o">.</span><span class="n">size_bytes</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">meta</span><span class="o">.</span><span class="n">size_bytes</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_encoding_ratio</span><span class="p">)</span>
            <span class="n">block_udf</span><span class="p">,</span> <span class="n">reader_args</span><span class="p">,</span> <span class="n">columns</span><span class="p">,</span> <span class="n">schema</span> <span class="o">=</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_block_udf</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_reader_args</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_columns</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_schema</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">read_tasks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">ReadTask</span><span class="p">(</span>
                    <span class="k">lambda</span> <span class="n">p</span><span class="o">=</span><span class="n">serialized_pieces</span><span class="p">:</span> <span class="n">_read_pieces</span><span class="p">(</span>
                        <span class="n">block_udf</span><span class="p">,</span>
                        <span class="n">reader_args</span><span class="p">,</span>
                        <span class="n">columns</span><span class="p">,</span>
                        <span class="n">schema</span><span class="p">,</span>
                        <span class="n">p</span><span class="p">,</span>
                    <span class="p">),</span>
                    <span class="n">meta</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="n">read_tasks</span>

    <span class="k">def</span> <span class="nf">_estimate_files_encoding_ratio</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Return an estimate of the Parquet files encoding ratio.</span>

<span class="sd">        To avoid OOMs, it is safer to return an over-estimate than an underestimate.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">DataContext</span><span class="o">.</span><span class="n">get_current</span><span class="p">()</span><span class="o">.</span><span class="n">decoding_size_estimation</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">PARQUET_ENCODING_RATIO_ESTIMATE_DEFAULT</span>

        <span class="c1"># Sample a few rows from Parquet files to estimate the encoding ratio.</span>
        <span class="c1"># Launch tasks to sample multiple files remotely in parallel.</span>
        <span class="c1"># Evenly distributed to sample N rows in i-th row group in i-th file.</span>
        <span class="c1"># TODO(ekl/cheng) take into account column pruning.</span>
        <span class="n">num_files</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_pq_ds</span><span class="o">.</span><span class="n">pieces</span><span class="p">)</span>
        <span class="n">num_samples</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">num_files</span> <span class="o">*</span> <span class="n">PARQUET_ENCODING_RATIO_ESTIMATE_SAMPLING_RATIO</span><span class="p">)</span>
        <span class="n">min_num_samples</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span>
            <span class="n">PARQUET_ENCODING_RATIO_ESTIMATE_MIN_NUM_SAMPLES</span><span class="p">,</span> <span class="n">num_files</span>
        <span class="p">)</span>
        <span class="n">max_num_samples</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span>
            <span class="n">PARQUET_ENCODING_RATIO_ESTIMATE_MAX_NUM_SAMPLES</span><span class="p">,</span> <span class="n">num_files</span>
        <span class="p">)</span>
        <span class="n">num_samples</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">num_samples</span><span class="p">,</span> <span class="n">max_num_samples</span><span class="p">),</span> <span class="n">min_num_samples</span><span class="p">)</span>

        <span class="c1"># Evenly distributed to choose which file to sample, to avoid biased prediction</span>
        <span class="c1"># if data is skewed.</span>
        <span class="n">file_samples</span> <span class="o">=</span> <span class="p">[</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_pq_ds</span><span class="o">.</span><span class="n">pieces</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_files</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
        <span class="p">]</span>

        <span class="n">sample_piece</span> <span class="o">=</span> <span class="n">cached_remote_fn</span><span class="p">(</span><span class="n">_sample_piece</span><span class="p">)</span>
        <span class="n">futures</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">scheduling</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_local_scheduling</span> <span class="ow">or</span> <span class="s2">&quot;SPREAD&quot;</span>
        <span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">file_samples</span><span class="p">:</span>
            <span class="c1"># Sample the first rows batch in i-th file.</span>
            <span class="c1"># Use SPREAD scheduling strategy to avoid packing many sampling tasks on</span>
            <span class="c1"># same machine to cause OOM issue, as sampling can be memory-intensive.</span>
            <span class="n">serialized_sample</span> <span class="o">=</span> <span class="n">_SerializedPiece</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
            <span class="n">futures</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">sample_piece</span><span class="o">.</span><span class="n">options</span><span class="p">(</span><span class="n">scheduling_strategy</span><span class="o">=</span><span class="n">scheduling</span><span class="p">)</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_reader_args</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_columns</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_schema</span><span class="p">,</span>
                    <span class="n">serialized_sample</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="n">sample_bar</span> <span class="o">=</span> <span class="n">ProgressBar</span><span class="p">(</span><span class="s2">&quot;Parquet Files Sample&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">futures</span><span class="p">))</span>
        <span class="n">sample_ratios</span> <span class="o">=</span> <span class="n">sample_bar</span><span class="o">.</span><span class="n">fetch_until_complete</span><span class="p">(</span><span class="n">futures</span><span class="p">)</span>
        <span class="n">sample_bar</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
        <span class="n">ratio</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">sample_ratios</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Estimated Parquet encoding ratio from sampling is </span><span class="si">{</span><span class="n">ratio</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">max</span><span class="p">(</span><span class="n">ratio</span><span class="p">,</span> <span class="n">PARQUET_ENCODING_RATIO_ESTIMATE_LOWER_BOUND</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_read_pieces</span><span class="p">(</span>
    <span class="n">block_udf</span><span class="p">,</span> <span class="n">reader_args</span><span class="p">,</span> <span class="n">columns</span><span class="p">,</span> <span class="n">schema</span><span class="p">,</span> <span class="n">serialized_pieces</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">_SerializedPiece</span><span class="p">]</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterator</span><span class="p">[</span><span class="s2">&quot;pyarrow.Table&quot;</span><span class="p">]:</span>
    <span class="c1"># This import is necessary to load the tensor extension type.</span>
    <span class="kn">from</span> <span class="nn">ray.data.extensions.tensor_extension</span> <span class="kn">import</span> <span class="n">ArrowTensorType</span>  <span class="c1"># noqa</span>

    <span class="c1"># Deserialize after loading the filesystem class.</span>
    <span class="n">pieces</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span>
        <span class="s2">&quot;pyarrow._dataset.ParquetFileFragment&quot;</span>
    <span class="p">]</span> <span class="o">=</span> <span class="n">_deserialize_pieces_with_retry</span><span class="p">(</span><span class="n">serialized_pieces</span><span class="p">)</span>

    <span class="c1"># Ensure that we&#39;re reading at least one dataset fragment.</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">pieces</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span>

    <span class="kn">import</span> <span class="nn">pyarrow</span> <span class="k">as</span> <span class="nn">pa</span>
    <span class="kn">from</span> <span class="nn">pyarrow.dataset</span> <span class="kn">import</span> <span class="n">_get_partition_keys</span>

    <span class="n">ctx</span> <span class="o">=</span> <span class="n">DataContext</span><span class="o">.</span><span class="n">get_current</span><span class="p">()</span>
    <span class="n">output_buffer</span> <span class="o">=</span> <span class="n">BlockOutputBuffer</span><span class="p">(</span>
        <span class="n">block_udf</span><span class="o">=</span><span class="n">block_udf</span><span class="p">,</span>
        <span class="n">target_max_block_size</span><span class="o">=</span><span class="n">ctx</span><span class="o">.</span><span class="n">target_max_block_size</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Reading </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">pieces</span><span class="p">)</span><span class="si">}</span><span class="s2"> parquet pieces&quot;</span><span class="p">)</span>
    <span class="n">use_threads</span> <span class="o">=</span> <span class="n">reader_args</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;use_threads&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">reader_args</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;batch_size&quot;</span><span class="p">,</span> <span class="n">PARQUET_READER_ROW_BATCH_SIZE</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">piece</span> <span class="ow">in</span> <span class="n">pieces</span><span class="p">:</span>
        <span class="n">part</span> <span class="o">=</span> <span class="n">_get_partition_keys</span><span class="p">(</span><span class="n">piece</span><span class="o">.</span><span class="n">partition_expression</span><span class="p">)</span>
        <span class="n">batches</span> <span class="o">=</span> <span class="n">piece</span><span class="o">.</span><span class="n">to_batches</span><span class="p">(</span>
            <span class="n">use_threads</span><span class="o">=</span><span class="n">use_threads</span><span class="p">,</span>
            <span class="n">columns</span><span class="o">=</span><span class="n">columns</span><span class="p">,</span>
            <span class="n">schema</span><span class="o">=</span><span class="n">schema</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="o">**</span><span class="n">reader_args</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">batches</span><span class="p">:</span>
            <span class="n">table</span> <span class="o">=</span> <span class="n">pa</span><span class="o">.</span><span class="n">Table</span><span class="o">.</span><span class="n">from_batches</span><span class="p">([</span><span class="n">batch</span><span class="p">],</span> <span class="n">schema</span><span class="o">=</span><span class="n">schema</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">part</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">col</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">part</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="n">table</span> <span class="o">=</span> <span class="n">table</span><span class="o">.</span><span class="n">set_column</span><span class="p">(</span>
                        <span class="n">table</span><span class="o">.</span><span class="n">schema</span><span class="o">.</span><span class="n">get_field_index</span><span class="p">(</span><span class="n">col</span><span class="p">),</span>
                        <span class="n">col</span><span class="p">,</span>
                        <span class="n">pa</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">value</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">table</span><span class="p">)),</span>
                    <span class="p">)</span>
            <span class="c1"># If the table is empty, drop it.</span>
            <span class="k">if</span> <span class="n">table</span><span class="o">.</span><span class="n">num_rows</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">output_buffer</span><span class="o">.</span><span class="n">add_block</span><span class="p">(</span><span class="n">table</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">output_buffer</span><span class="o">.</span><span class="n">has_next</span><span class="p">():</span>
                    <span class="k">yield</span> <span class="n">output_buffer</span><span class="o">.</span><span class="n">next</span><span class="p">()</span>
    <span class="n">output_buffer</span><span class="o">.</span><span class="n">finalize</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">output_buffer</span><span class="o">.</span><span class="n">has_next</span><span class="p">():</span>
        <span class="k">yield</span> <span class="n">output_buffer</span><span class="o">.</span><span class="n">next</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">_fetch_metadata_serialization_wrapper</span><span class="p">(</span>
    <span class="n">pieces</span><span class="p">:</span> <span class="n">_SerializedPiece</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="s2">&quot;pyarrow.parquet.FileMetaData&quot;</span><span class="p">]:</span>
    <span class="n">pieces</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span>
        <span class="s2">&quot;pyarrow._dataset.ParquetFileFragment&quot;</span>
    <span class="p">]</span> <span class="o">=</span> <span class="n">_deserialize_pieces_with_retry</span><span class="p">(</span><span class="n">pieces</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">_fetch_metadata</span><span class="p">(</span><span class="n">pieces</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_fetch_metadata</span><span class="p">(</span>
    <span class="n">pieces</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="s2">&quot;pyarrow.dataset.ParquetFileFragment&quot;</span><span class="p">],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="s2">&quot;pyarrow.parquet.FileMetaData&quot;</span><span class="p">]:</span>
    <span class="n">piece_metadata</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">pieces</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">piece_metadata</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">metadata</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
            <span class="k">break</span>
    <span class="k">return</span> <span class="n">piece_metadata</span>


<span class="k">def</span> <span class="nf">_sample_piece</span><span class="p">(</span>
    <span class="n">reader_args</span><span class="p">,</span>
    <span class="n">columns</span><span class="p">,</span>
    <span class="n">schema</span><span class="p">,</span>
    <span class="n">file_piece</span><span class="p">:</span> <span class="n">_SerializedPiece</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="c1"># Sample the first rows batch from file piece `serialized_piece`.</span>
    <span class="c1"># Return the encoding ratio calculated from the sampled rows.</span>
    <span class="n">piece</span> <span class="o">=</span> <span class="n">_deserialize_pieces_with_retry</span><span class="p">([</span><span class="n">file_piece</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># Only sample the first row group.</span>
    <span class="n">piece</span> <span class="o">=</span> <span class="n">piece</span><span class="o">.</span><span class="n">subset</span><span class="p">(</span><span class="n">row_group_ids</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span>
        <span class="nb">min</span><span class="p">(</span><span class="n">piece</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">num_rows</span><span class="p">,</span> <span class="n">PARQUET_ENCODING_RATIO_ESTIMATE_NUM_ROWS</span><span class="p">),</span> <span class="mi">1</span>
    <span class="p">)</span>
    <span class="c1"># Use the batch_size calculated above, and ignore the one specified by user if set.</span>
    <span class="c1"># This is to avoid sampling too few or too many rows.</span>
    <span class="n">reader_args</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;batch_size&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="n">batches</span> <span class="o">=</span> <span class="n">piece</span><span class="o">.</span><span class="n">to_batches</span><span class="p">(</span>
        <span class="n">columns</span><span class="o">=</span><span class="n">columns</span><span class="p">,</span>
        <span class="n">schema</span><span class="o">=</span><span class="n">schema</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
        <span class="o">**</span><span class="n">reader_args</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="c1"># Use first batch in-memory size as ratio estimation.</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">batches</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">StopIteration</span><span class="p">:</span>
        <span class="n">ratio</span> <span class="o">=</span> <span class="n">PARQUET_ENCODING_RATIO_ESTIMATE_LOWER_BOUND</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">batch</span><span class="o">.</span><span class="n">num_rows</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">in_memory_size</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">nbytes</span> <span class="o">/</span> <span class="n">batch</span><span class="o">.</span><span class="n">num_rows</span>
            <span class="n">metadata</span> <span class="o">=</span> <span class="n">piece</span><span class="o">.</span><span class="n">metadata</span>
            <span class="n">total_size</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">metadata</span><span class="o">.</span><span class="n">num_row_groups</span><span class="p">):</span>
                <span class="n">total_size</span> <span class="o">+=</span> <span class="n">metadata</span><span class="o">.</span><span class="n">row_group</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span><span class="o">.</span><span class="n">total_byte_size</span>
            <span class="n">file_size</span> <span class="o">=</span> <span class="n">total_size</span> <span class="o">/</span> <span class="n">metadata</span><span class="o">.</span><span class="n">num_rows</span>
            <span class="n">ratio</span> <span class="o">=</span> <span class="n">in_memory_size</span> <span class="o">/</span> <span class="n">file_size</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">ratio</span> <span class="o">=</span> <span class="n">PARQUET_ENCODING_RATIO_ESTIMATE_LOWER_BOUND</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;Estimated Parquet encoding ratio is </span><span class="si">{</span><span class="n">ratio</span><span class="si">}</span><span class="s2"> for piece </span><span class="si">{</span><span class="n">piece</span><span class="si">}</span><span class="s2"> &quot;</span>
        <span class="sa">f</span><span class="s2">&quot;with batch size </span><span class="si">{</span><span class="n">batch_size</span><span class="si">}</span><span class="s2">.&quot;</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">ratio</span>
</pre></div>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By The Ray Team<br/>
  
      &copy; Copyright 2023, The Ray Team.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../../_static/scripts/pydata-sphinx-theme.js@digest=1999514e3f237ded88cf"></script>


  </body>
</html>